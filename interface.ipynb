{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5cb7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Extracted Table:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"tables\": [\n",
      "        {\n",
      "            \"table_title\": \"Demographic characteristics of the participants (n = 145)\",\n",
      "            \"is_baseline\": true,\n",
      "            \"group_ns\": { \"Growth hormone group\": 72, \"Microflare only group\": 73 },\n",
      "            \"headers\": [\"Characteristic\", \"Growth hormone group\", \"Microflare only group\", \"P value\"],\n",
      "            \"data\": [\n",
      "                [\"Age, y\", \"34.9 Â± 4.8\", \"34.8 Â± 5.6\", \"0.812\"],\n",
      "                [\"Duration of infertility, y\", \"7.3 Â± 3.5\", \"7.5 Â± 3.4\", \"0.636\"],\n",
      "                [\"Anti-MÃ¼llerian hormone level, ng/mL\", \"0.4 Â± 0.2\", \"0.5 Â± 0.2\", \"0.744\"],\n",
      "                [\"Day 3 follicle-stimulating hormone level, IU/L\", \"10.2 Â± 2.9\", \"9.9 Â± 2.3\", \"0.548\"],\n",
      "                [\"BMI\", \"23.3 Â± 3.6\", \"23.3 Â± 3.6\", \"0.939\"],\n",
      "                [\"Antral follicle count\", \"5.9 Â± 1.6\", \"5.9 Â± 1.7\", \"0.761\"],\n",
      "                [\"No. of previous poor responses\", \"2.4 Â± 1.5\", \"2.7 Â± 1.5\", \"0.277\"]\n",
      "            ],\n",
      "            \"table_note\": \"BMI, body mass index (calculated as weight in kilograms divided by the square of height in meters). a Values given as mean Â± SD unless indicated otherwise. b All participants underwent microflare stimulation protocol (oral contraceptive pills, human menopausal gonadotropin, and a microdose of gonadotropin-releasing hormone analog).\"\n",
      "        },\n",
      "        {\n",
      "            \"table_title\": \"Characteristics of the controlled ovarian stimulation cycles\",\n",
      "            \"is_baseline\": false,\n",
      "            \"group_ns\": { \"Growth hormone group\": 72, \"Microflare only group\": 73 },\n",
      "            \"headers\": [\"Characteristic\", \"Growth hormone group\", \"Microflare only group\", \"P value\"],\n",
      "            \"data\": [\n",
      "                [\"HMG dose, IU\", \"3855.2 Â± 895.5\", \"3744.8 Â± 1326.6\", \"<0.001\"],\n",
      "                [\"HMG duration, d\", \"10.3 Â± 1.2\", \"11.7 Â± 1.2\", \"<0.001\"],\n",
      "                [\"Endometrial thickness, mm\", \"11.8 Â± 1.4\", \"11.7 Â± 1.7\", \"0.590\"],\n",
      "                [\"Estradiol, pg/mL\", \"2013.8 Â± 354.4\", \"999.8 Â± 372.7\", \"<0.001\"],\n",
      "                [\"Luteinizing hormone, IU/L c\", \"1.9 Â± 1.3\", \"7.2 Â± 1.1\", \"<0.001\"],\n",
      "                [\"Progesterone, ng/mL c\", \"1.0 Â± 0.3\", \"1.0 Â± 0.3\", \"0.670\"],\n",
      "                [\"No. of oocytes collected\", \"7.2 Â± 1.5\", \"4.7 Â± 1.2\", \"<0.001\"],\n",
      "                [\"No. of metaphase II oocytes\", \"5.2 Â± 1.2\", \"2.8 Â± 1.0\", \"<0.001\"]\n",
      "            ],\n",
      "            \"table_note\": \"Abbreviation: HMG, human menopausal gonadotropin. a Values given as mean Â± standard deviation unless indicated otherwise. b All participants underwent microflare stimulation protocol (oral contraceptive pills, human menopausal gonadotropin, and a microdose of gonadotropin-releasing hormone analog). c On day of triggering with human chorionic gonadotropin.\"\n",
      "        },\n",
      "        {\n",
      "            \"table_title\": \"Outcomes of the ovarian stimulation cycles\",\n",
      "            \"is_baseline\": false,\n",
      "            \"group_ns\": { \"Growth hormone group\": 72, \"Microflare only group\": 73 },\n",
      "            \"headers\": [\"Outcome\", \"Growth hormone group\", \"Microflare only group\", \"P value\"],\n",
      "            \"data\": [\n",
      "                [\"No. of fertilized oocytes\", \"4.2 Â± 1.1\", \"2.5 Â± 0.7\", \"<0.001\"],\n",
      "                [\"No. of embryos transferred\", \"2.9 Â± 0.7\", \"2.1 Â± 0.6\", \"<0.001\"],\n",
      "                [\"Fertilization rate, %\", \"58.1\", \"50.5\", \"0.001\"],\n",
      "                [\"Implantation rate, %\", \"19.6\", \"11.6\", \"0.090\"],\n",
      "                [\"Clinical pregnancy\", \"24 (33.3)\", \"15 (20.5)\", \"0.083\"]\n",
      "            ],\n",
      "            \"table_note\": \"a Values given as mean Â± standard deviation, percentage, or number (percentage), unless indicated otherwise. b All participants underwent microflare stimulation protocol (oral contraceptive pills, human menopausal gonadotropin, and a microdose of gonadotropin-releasing hormone analog). c All outcomes were calculated per transfer; canceled cycles were not included in the analysis.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "ðŸ“‹ Splited Table:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"tables\": [\n",
      "        {\n",
      "            \"table_title\": \"Demographic characteristics of the participants (n = 145)\",\n",
      "            \"is_baseline\": true,\n",
      "            \"group_ns\": { \"Growth hormone group\": 72, \"Microflare only group\": 73 },\n",
      "            \"headers\": [\"Characteristic\", \"Growth hormone group\", \"Growth hormone group Mean\", \"Growth hormone group SD\", \"Microflare only group\", \"Microflare only group Mean\", \"Microflare only group SD\", \"P value\"],\n",
      "            \"data\": [\n",
      "                [\"Age, y\", \"34.9 Â± 4.8\", \"34.9\", \"4.8\", \"34.8 Â± 5.6\", \"34.8\", \"5.6\", \"0.812\"],\n",
      "                [\"Duration of infertility, y\", \"7.3 Â± 3.5\", \"7.3\", \"3.5\", \"7.5 Â± 3.4\", \"7.5\", \"3.4\", \"0.636\"],\n",
      "                [\"Anti-MÃ¼llerian hormone level, ng/mL\", \"0.4 Â± 0.2\", \"0.4\", \"0.2\", \"0.5 Â± 0.2\", \"0.5\", \"0.2\", \"0.744\"],\n",
      "                [\"Day 3 follicle-stimulating hormone level, IU/L\", \"10.2 Â± 2.9\", \"10.2\", \"2.9\", \"9.9 Â± 2.3\", \"9.9\", \"2.3\", \"0.548\"],\n",
      "                [\"BMI\", \"23.3 Â± 3.6\", \"23.3\", \"3.6\", \"23.3 Â± 3.6\", \"23.3\", \"3.6\", \"0.939\"],\n",
      "                [\"Antral follicle count\", \"5.9 Â± 1.6\", \"5.9\", \"1.6\", \"5.9 Â± 1.7\", \"5.9\", \"1.7\", \"0.761\"],\n",
      "                [\"No. of previous poor responses\", \"2.4 Â± 1.5\", \"2.4\", \"1.5\", \"2.7 Â± 1.5\", \"2.7\", \"1.5\", \"0.277\"]\n",
      "            ],\n",
      "            \"table_note\": \"BMI, body mass index (calculated as weight in kilograms divided by the square of height in meters). a Values given as mean Â± SD unless indicated otherwise. b All participants underwent microflare stimulation protocol (oral contraceptive pills, human menopausal gonadotropin, and a microdose of gonadotropin-releasing hormone analog).\"\n",
      "        },\n",
      "        {\n",
      "            \"table_title\": \"Characteristics of the controlled ovarian stimulation cycles\",\n",
      "            \"is_baseline\": false,\n",
      "            \"group_ns\": { \"Growth hormone group\": 72, \"Microflare only group\": 73 },\n",
      "            \"headers\": [\"Characteristic\", \"Growth hormone group\", \"Growth hormone group Mean\", \"Growth hormone group SD\", \"Microflare only group\", \"Microflare only group Mean\", \"Microflare only group SD\", \"P value\"],\n",
      "            \"data\": [\n",
      "                [\"HMG dose, IU\", \"3855.2 Â± 895.5\", \"3855.2\", \"895.5\", \"3744.8 Â± 1326.6\", \"3744.8\", \"1326.6\", \"<0.001\"],\n",
      "                [\"HMG duration, d\", \"10.3 Â± 1.2\", \"10.3\", \"1.2\", \"11.7 Â± 1.2\", \"11.7\", \"1.2\", \"<0.001\"],\n",
      "                [\"Endometrial thickness, mm\", \"11.8 Â± 1.4\", \"11.8\", \"1.4\", \"11.7 Â± 1.7\", \"11.7\", \"1.7\", \"0.590\"],\n",
      "                [\"Estradiol, pg/mL\", \"2013.8 Â± 354.4\", \"2013.8\", \"354.4\", \"999.8 Â± 372.7\", \"999.8\", \"372.7\", \"<0.001\"],\n",
      "                [\"Luteinizing hormone, IU/L c\", \"1.9 Â± 1.3\", \"1.9\", \"1.3\", \"7.2 Â± 1.1\", \"7.2\", \"1.1\", \"<0.001\"],\n",
      "                [\"Progesterone, ng/mL c\", \"1.0 Â± 0.3\", \"1.0\", \"0.3\", \"1.0 Â± 0.3\", \"1.0\", \"0.3\", \"0.670\"],\n",
      "                [\"No. of oocytes collected\", \"7.2 Â± 1.5\", \"7.2\", \"1.5\", \"4.7 Â± 1.2\", \"4.7\", \"1.2\", \"<0.001\"],\n",
      "                [\"No. of metaphase II oocytes\", \"5.2 Â± 1.2\", \"5.2\", \"1.2\", \"2.8 Â± 1.0\", \"2.8\", \"1.0\", \"<0.001\"]\n",
      "            ],\n",
      "            \"table_note\": \"Abbreviation: HMG, human menopausal gonadotropin. a Values given as mean Â± standard deviation unless indicated otherwise. b All participants underwent microflare stimulation protocol (oral contraceptive pills, human menopausal gonadotropin, and a microdose of gonadotropin-releasing hormone analog). c On day of triggering with human chorionic gonadotropin.\"\n",
      "        },\n",
      "        {\n",
      "            \"table_title\": \"Outcomes of the ovarian stimulation cycles\",\n",
      "            \"is_baseline\": false,\n",
      "            \"group_ns\": { \"Growth hormone group\": 72, \"Microflare only group\": 73 },\n",
      "            \"headers\": [\"Outcome\", \"Growth hormone group\", \"Growth hormone group Mean\", \"Growth hormone group SD\", \"Microflare only group\", \"Microflare only group Mean\", \"Microflare only group SD\", \"P value\"],\n",
      "            \"data\": [\n",
      "                [\"No. of fertilized oocytes\", \"4.2 Â± 1.1\", \"4.2\", \"1.1\", \"2.5 Â± 0.7\", \"2.5\", \"0.7\", \"<0.001\"],\n",
      "                [\"No. of embryos transferred\", \"2.9 Â± 0.7\", \"2.9\", \"0.7\", \"2.1 Â± 0.6\", \"2.1\", \"0.6\", \"<0.001\"],\n",
      "                [\"Fertilization rate, %\", \"58.1\", \"\", \"\", \"50.5\", \"\", \"\", \"0.001\"],\n",
      "                [\"Implantation rate, %\", \"19.6\", \"\", \"\", \"11.6\", \"\", \"\", \"0.090\"],\n",
      "                [\"Clinical pregnancy\", \"24 (33.3)\", \"\", \"\", \"15 (20.5)\", \"\", \"\", \"0.083\"]\n",
      "            ],\n",
      "            \"table_note\": \"a Values given as mean Â± standard deviation, percentage, or number (percentage), unless indicated otherwise. b All participants underwent microflare stimulation protocol (oral contraceptive pills, human menopausal gonadotropin, and a microdose of gonadotropin-releasing hormone analog). c All outcomes were calculated per transfer; canceled cycles were not included in the analysis.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import logging\n",
    "import tempfile\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "\n",
    "# PDF/table tools (you already used these in your original script)\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# OpenAI client - placeholder, keep your existing initialization\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- CONFIG --- replace with your real values via environment variables\n",
    "AZURE_DEPLOYMENT = os.getenv(\"DEPLOYMENT_NAME\", \"gpt-4o\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # replace securely\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ------------------------\n",
    "# Utilities\n",
    "# ------------------------\n",
    "def encode_image_to_base64(path: str) -> str:\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode()\n",
    "\n",
    "def make_pdf_iframe(path: str):\n",
    "    b64 = base64.b64encode(open(path,\"rb\").read()).decode()\n",
    "    return f'<iframe src=\"data:application/pdf;base64,{b64}\" width=\"600\" height=\"800\" style=\"border:none;\"></iframe>'\n",
    "\n",
    "RE_MEAN_SD = re.compile(r'^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*(?:Â±|\\+/-|\\u00B1)\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*$')\n",
    "RE_PAREN = re.compile(r'^\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*\\(\\s*([+-]?\\d+(?:\\.\\d+)?)\\s*\\)\\s*$')\n",
    "\n",
    "def parse_mean_sd_cell(cell):\n",
    "    \"\"\"Try to parse 'mean Â± sd' or 'mean(sd)' patterns; else None.\"\"\"\n",
    "    if pd.isna(cell):\n",
    "        return None\n",
    "    s = str(cell).strip()\n",
    "    m = RE_MEAN_SD.match(s)\n",
    "    if m:\n",
    "        return float(m.group(1)), float(m.group(2))\n",
    "    m2 = RE_PAREN.match(s)\n",
    "    if m2:\n",
    "        return float(m2.group(1)), float(m2.group(2))\n",
    "    return None\n",
    "\n",
    "# ------------------------\n",
    "# f_range and ANOVA-from-summaries (simplified & robust)\n",
    "# (We implement a version suited to 1D (k groups) or 2D (a x b) cells.)\n",
    "# ------------------------\n",
    "def _anova_oneway_from_summaries(m, s, n):\n",
    "    m = np.asarray(m, dtype=float)\n",
    "    s = np.asarray(s, dtype=float)\n",
    "    n = np.asarray(n, dtype=float)\n",
    "    k = len(m)\n",
    "    N = np.sum(n)\n",
    "    if k < 2:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    grand_mean = np.sum(n * m) / N\n",
    "    ss_between = np.sum(n * (m - grand_mean) ** 2)\n",
    "    ss_within = np.sum((n - 1.0) * (s ** 2))\n",
    "    df_between = k - 1\n",
    "    df_within = int(np.sum(n) - k)\n",
    "    if df_between <= 0 or df_within <= 0:\n",
    "        return np.nan, df_between, df_within\n",
    "    ms_between = ss_between / df_between\n",
    "    ms_within = ss_within / df_within\n",
    "    F = ms_between / ms_within if ms_within != 0 else np.nan\n",
    "    return F, df_between, df_within\n",
    "\n",
    "def _anova_twoway_from_summaries(m, s, n):\n",
    "    m = np.asarray(m, dtype=float)\n",
    "    s = np.asarray(s, dtype=float)\n",
    "    n = np.asarray(n, dtype=float)\n",
    "    if m.ndim != 2:\n",
    "        raise ValueError(\"m must be 2D for two-way ANOVA\")\n",
    "    a, b = m.shape\n",
    "    N = np.sum(n)\n",
    "    grand_mean = np.sum(n * m) / N\n",
    "    ss_within = np.sum((n - 1.0) * (s ** 2))\n",
    "    ss_treatment = np.sum(n * (m - grand_mean) ** 2)\n",
    "    n_row = np.sum(n, axis=1)\n",
    "    mean_row = np.sum(n * m, axis=1) / n_row\n",
    "    n_col = np.sum(n, axis=0)\n",
    "    mean_col = np.sum(n * m, axis=0) / n_col\n",
    "    ss_A = np.sum(n_row * (mean_row - grand_mean) ** 2)\n",
    "    ss_B = np.sum(n_col * (mean_col - grand_mean) ** 2)\n",
    "    ss_AB = ss_treatment - ss_A - ss_B\n",
    "    df_A = a - 1\n",
    "    df_B = b - 1\n",
    "    df_AB = (a - 1) * (b - 1)\n",
    "    df_within = int(np.sum(n) - a * b)\n",
    "    if df_within <= 0:\n",
    "        return [np.nan, np.nan, np.nan], [df_A, df_B, df_AB, df_within]\n",
    "    ms_A = ss_A / df_A if df_A > 0 else np.nan\n",
    "    ms_B = ss_B / df_B if df_B > 0 else np.nan\n",
    "    ms_AB = ss_AB / df_AB if df_AB > 0 else np.nan\n",
    "    ms_within = ss_within / df_within\n",
    "    F_A = ms_A / ms_within if ms_within != 0 else np.nan\n",
    "    F_B = ms_B / ms_within if ms_within != 0 else np.nan\n",
    "    F_AB = ms_AB / ms_within if ms_within != 0 else np.nan\n",
    "    return [F_A, F_B, F_AB], [df_A, df_B, df_AB, df_within]\n",
    "\n",
    "def f_range(m, s, n, title=None, show_t=False, dp_p=-1, labels=None, max_enumeration=2**16):\n",
    "    \"\"\"\n",
    "    Compute nominal, min and max plausible F (or t if show_t=True) values\n",
    "    given reported means, sds, ns, allowing for rounding error.\n",
    "    Works for 1D (one-way) and 2D (two-way) cell arrays.\n",
    "    \"\"\"\n",
    "    m_arr = np.array(m)\n",
    "    s_arr = np.array(s)\n",
    "    n_arr = np.array(n)\n",
    "\n",
    "    # detect decimals\n",
    "    dp = dp_p\n",
    "    if dp_p == -1:\n",
    "        dp = 0\n",
    "        numbers = np.concatenate([np.ravel(m_arr).astype(float), np.ravel(s_arr).astype(float)])\n",
    "        for x in numbers:\n",
    "            if not np.isclose(x, np.round(x, 0)):\n",
    "                dp = max(dp, 1)\n",
    "                if not np.isclose(x * 10, np.round(x * 10, 0)):\n",
    "                    dp = max(dp, 2)\n",
    "    delta = (0.1 ** dp) / 2.0\n",
    "\n",
    "    # nominal\n",
    "    if m_arr.ndim == 1:\n",
    "        f_nom, _, _ = _anova_oneway_from_summaries(m_arr, s_arr, n_arr)\n",
    "        useFs = [f_nom]\n",
    "        default_labels = [\"F\" if not show_t else \"t\"]\n",
    "    elif m_arr.ndim == 2:\n",
    "        Fs_nom, _ = _anova_twoway_from_summaries(m_arr, s_arr, n_arr)\n",
    "        useFs = Fs_nom\n",
    "        default_labels = [\"A F\", \"B F\", \"A:B F\"]\n",
    "    else:\n",
    "        raise ValueError(\"m must be 1D or 2D array-like\")\n",
    "\n",
    "    m_flat = np.ravel(m_arr)\n",
    "    s_flat = np.ravel(s_arr)\n",
    "    n_flat = np.ravel(n_arr)\n",
    "    l = len(m_flat)\n",
    "\n",
    "    total_combinations = 2 ** l\n",
    "    if total_combinations > max_enumeration:\n",
    "        enumeration_mode = \"sampled\"\n",
    "        rng = np.random.default_rng(12345)\n",
    "        sampled_codes = rng.choice(total_combinations, size=max_enumeration, replace=False)\n",
    "    else:\n",
    "        enumeration_mode = \"full\"\n",
    "        sampled_codes = None\n",
    "\n",
    "    eps = 1e-8\n",
    "    s_hi = np.maximum(s_flat - delta, eps)\n",
    "    s_lo = s_flat + delta\n",
    "\n",
    "    f_hi = np.array(useFs, dtype=float)\n",
    "    f_lo = np.array(useFs, dtype=float)\n",
    "\n",
    "    def compute_for_signs(sign_vector):\n",
    "        m_adj = (m_flat + sign_vector)\n",
    "        if m_arr.ndim == 1:\n",
    "            F_hi, _, _ = _anova_oneway_from_summaries(m_adj, s_hi, n_flat)\n",
    "            F_lo, _, _ = _anova_oneway_from_summaries(m_adj, s_lo, n_flat)\n",
    "            return [F_hi], [F_lo]\n",
    "        else:\n",
    "            a, b = m_arr.shape\n",
    "            m_adj_mat = m_adj.reshape(a, b)\n",
    "            s_hi_mat = s_hi.reshape(a, b)\n",
    "            s_lo_mat = s_lo.reshape(a, b)\n",
    "            F_hi_list, _ = _anova_twoway_from_summaries(m_adj_mat, s_hi_mat, n_arr)\n",
    "            F_lo_list, _ = _anova_twoway_from_summaries(m_adj_mat, s_lo_mat, n_arr)\n",
    "            return F_hi_list, F_lo_list\n",
    "\n",
    "    if enumeration_mode == \"full\":\n",
    "        for signs in itertools.product([-delta, delta], repeat=l):\n",
    "            sign_vec = np.array(signs)\n",
    "            F_hi_list, F_lo_list = compute_for_signs(sign_vec)\n",
    "            f_hi = np.maximum(f_hi, np.array(F_hi_list, dtype=float))\n",
    "            f_lo = np.minimum(f_lo, np.array(F_lo_list, dtype=float))\n",
    "    else:\n",
    "        for code in sampled_codes:\n",
    "            sign_vector = np.array([delta if ((code >> i) & 1) == 1 else -delta for i in range(l)])\n",
    "            F_hi_list, F_lo_list = compute_for_signs(sign_vector)\n",
    "            f_hi = np.maximum(f_hi, np.array(F_hi_list, dtype=float))\n",
    "            f_lo = np.minimum(f_lo, np.array(F_lo_list, dtype=float))\n",
    "\n",
    "    if show_t:\n",
    "        f_nom_out = np.sqrt(np.clip(np.array(useFs, dtype=float), a_min=0.0, a_max=None))\n",
    "        f_hi = np.sqrt(np.clip(f_hi, a_min=0.0, a_max=None))\n",
    "        f_lo = np.sqrt(np.clip(f_lo, a_min=0.0, a_max=None))\n",
    "    else:\n",
    "        f_nom_out = np.array(useFs, dtype=float)\n",
    "\n",
    "    labels_out = labels if (labels is not None and len(labels) == len(f_nom_out)) else default_labels\n",
    "    result = {\n",
    "        \"title\": title,\n",
    "        \"labels\": labels_out,\n",
    "        \"nominal\": [None if np.isnan(x) else float(x) for x in f_nom_out],\n",
    "        \"min\": [None if np.isnan(x) else float(x) for x in f_lo],\n",
    "        \"max\": [None if np.isnan(x) else float(x) for x in f_hi],\n",
    "        \"dp\": int(dp),\n",
    "        \"enumeration_mode\": enumeration_mode,\n",
    "        \"total_combinations\": total_combinations\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def extract_ai(pdf_path):\n",
    "    pil_pages = convert_from_path(pdf_path, dpi=200)\n",
    "\n",
    "    image_blocks = []\n",
    "    for idx, img in enumerate(pil_pages, start=1):\n",
    "        tmp = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False)\n",
    "        tmp.close()\n",
    "        img.save(tmp.name, format=\"PNG\")\n",
    "        b64 = encode_image_to_base64(tmp.name)\n",
    "        os.unlink(tmp.name)\n",
    "        image_blocks.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/png;base64,{b64}\"}\n",
    "        })\n",
    "    messages = []\n",
    "    content = [\n",
    "            {\"type\": \"text\",\n",
    "             \"text\":f'''Please extract all exist tables from the following image and return them in json format with datas and headers in exactly same\n",
    "             format,make sure that all numerical values are extracted with full accuracy,do not change any format or name,include keys: table title and table note,is_baseline indicate whether the table is baseline table.\n",
    "             Example JSON output(please do not include this one):\n",
    "             ```json\n",
    "            {{\n",
    "            \"tables\": [\n",
    "                {{\n",
    "                \"table_title\": \"Patient Characteristics\",\n",
    "                \"is_baseline\": true,\n",
    "                \"group_ns\": {{ \"Study Group\": 50, \"Control Group\": 48 }}  // optional: integer N or null\n",
    "                \"headers\": [\"Feature\", \"Study Group\", \"Control Group\", \"P-value\"],\n",
    "                \"data\": [\n",
    "                    [\"Age (years)\", \"30 Â± 3.51\", \"29.2 Â± 2.93\", \".76\"],\n",
    "                    [\"Height (cm)\", \"158 Â± 12.33\", \"164 Â± 14.55\", \".54\"],\n",
    "                    [\"Body weight (kg)\", \"68 Â± 3.20\", \"65 Â± 4.21\", \".12\"]\n",
    "                ],\n",
    "                \"table_note\": \"Baseline characteristics of patients.\"\n",
    "                }},\n",
    "                {{\n",
    "                \"table_title\": \"Outcome 8 months after therapy\",\n",
    "                \"is_baseline\": false,\n",
    "                \"group_ns\": {{ \"Study Group\": 50, \"Control Group\": 48 }}  // optional: integer N or null\n",
    "                \"headers\": [\"Outcome\", \"Study Group\", \"Control Group\", \"P-value\"],\n",
    "                \"data\": [\n",
    "                    [\"Menstruating\", \"35 (89.6%)\", \"13 (33.3%)\", \"<.001*\"],\n",
    "                    [\"Ovulating\", \"27 (69.2%)\", \"10 (25.6%)\", \"<.001*\"],\n",
    "                    [\"POF\", \"4 (11.4%)\", \"21 (66.6%)\", \"<.001*\"]\n",
    "                ],\n",
    "                \"table_note\": \"P-value < .05 was considered statistically significant.\"\n",
    "                }}\n",
    "                ]\n",
    "            }}\n",
    "            ```\n",
    "             if no table,return No table provided:\\n\\n'''\n",
    "            }]+ image_blocks\n",
    "    messages.append({\"role\": 'user', \"content\": content})\n",
    "    # Call the API to generate the table extraction\n",
    "    completion = client.chat.completions.create(\n",
    "        model=AZURE_DEPLOYMENT,\n",
    "        messages=messages,\n",
    "        max_tokens=8000,\n",
    "        temperature=0.0,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    print(\"\\nðŸ“‹ Extracted Table:\\n\")\n",
    "    extract_tables = completion.choices[0].message.content\n",
    "    print(extract_tables)\n",
    "    chat_prompt_split=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a data analysis expert.\"},\n",
    "        {\"role\": \"user\", \"content\": f'''Please separate the Mean Standard Deviation (SD) into different columns inside all the following tables,\n",
    "        return all tables even they remain unchanged,only return data,no explaintions,if no table,return No table provided,here is a example\n",
    "        Example(DO NOT include this one):\n",
    "        ```json\n",
    "            {{\n",
    "            \"tables\": [\n",
    "                {{\n",
    "                \"table_title\": \"Patient Characteristics\",\n",
    "                \"is_baseline\": true,\n",
    "                \"group_ns\": {{ \"Study Group\": 50, \"Control Group\": 48 }}  // optional: integer N or null\n",
    "                \"headers\": [\"Feature\", \"Study Group\",\"Study Group Mean\",\"Study Group SD\", \"Control Group\",\"Control Group Mean\",\"Control Group SD\",\"P-value\"],\n",
    "                \"data\": [\n",
    "                    [\"Age (years)\", \"30 Â± 3.51\",\"30\", \"3.51\",\"29.2 Â± 2.93\",\"29.2\",\"2.93\", \".76\"],\n",
    "                    [\"Height (cm)\", \"158 Â± 12.33\",\"158\", \"12.33\",\"164 Â± 14.55\",\"164\",\"14.55\", \".54\"],\n",
    "                    [\"Body weight (kg)\", \"68 Â± 3.20\",\"68\", \"3.20\",\"65 Â± 4.21\",\"65\", \"4.21\",\".12\"]\n",
    "                ],\n",
    "                \"table_note\": \"Baseline characteristics of patients.\"\n",
    "                }},\n",
    "                {{\n",
    "                \"table_title\": \"Outcome 8 months after therapy\",\n",
    "                \"group_ns\": {{ \"Study Group\": 50, \"Control Group\": 48 }}  // optional: integer N or null\n",
    "                \"is_baseline\": false,\n",
    "                \"headers\": [\"Outcome\", \"Study Group\", \"Control Group\", \"P-value\"],\n",
    "                \"data\": [\n",
    "                    [\"Menstruating\", \"35 (89.6%)\", \"13 (33.3%)\", \"<.001*\"],\n",
    "                    [\"Ovulating\", \"27 (69.2%)\", \"10 (25.6%)\", \"<.001*\"],\n",
    "                    [\"POF\", \"4 (11.4%)\", \"21 (66.6%)\", \"<.001*\"]\n",
    "                ],\n",
    "                \"table_note\": \"P-value < .05 was considered statistically significant.\"\n",
    "                }}\n",
    "                ]\n",
    "            }}\n",
    "        ```\n",
    "         :\\n\\n{extract_tables}'''}\n",
    "    ]\n",
    "    messages = chat_prompt_split\n",
    "    completion = client.chat.completions.create(\n",
    "        model=AZURE_DEPLOYMENT,\n",
    "        messages=messages,\n",
    "        max_tokens=8000,\n",
    "        temperature=0.0,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False\n",
    "    )\n",
    "    print(\"\\nðŸ“‹ Splited Table:\\n\")\n",
    "    print(completion.choices[0].message.content)\n",
    "    json_str = completion.choices[0].message.content\n",
    "    json_str = json_str.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Not JSONï¼š{e}\\nï¼š\\n{json_str}\")\n",
    "\n",
    "    output_path = \"extracted_tables.json\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_ai_data(files):\n",
    "    \"\"\"Use image->LLM route - adapted to also expect group_ns in LLM output (similar to above).\"\"\"\n",
    "    if not files:\n",
    "        return [], [], \"\", {}\n",
    "    pdf_path = files[0]\n",
    "    b64 = base64.b64encode(open(pdf_path, \"rb\").read()).decode()\n",
    "    html_iframe = f'<iframe src=\"data:application/pdf;base64,{b64}\" width=\"600\" height=\"800\" style=\"border:none;\"></iframe>'\n",
    "    # For brevity call the same LLM prompt on image text: (you can implement image blocks like your original)\n",
    "    # Here we assume you already have a function extract_ai that returns the same JSON schema as above.\n",
    "    # We'll reuse the same JSON parsing logic: extract_ai() => json_str\n",
    "    # For this combined example, we just call a dummy extract_ai that you have in original script.\n",
    "    json_str = extract_ai(pdf_path)  # expects same output schema with group_ns\n",
    "    try:\n",
    "        data = json.loads(json_str.replace(\"```json\", \"\").replace(\"```\", \"\").strip())\n",
    "    except Exception:\n",
    "        clean = json_str.strip(\"```json\").strip(\"```\")\n",
    "        data = json.loads(clean)\n",
    "    tables = data.get(\"tables\", [])\n",
    "    names  = [t.get(\"table_title\", f\"table {i}\") for i, t in enumerate(tables)]\n",
    "    dfs    = [pd.DataFrame(t[\"data\"], columns=t[\"headers\"]) for t in tables]\n",
    "    pdf_name = Path(pdf_path).name\n",
    "    state = {\n",
    "      \"pdf_names\":    [pdf_name],\n",
    "      \"table_names\":  [names],\n",
    "      \"tables\":       [dfs],\n",
    "      \"table_ns\":     [[t.get(\"group_ns\", {}) for t in tables]],\n",
    "      \"iframes\":      [html_iframe],\n",
    "    }\n",
    "    return [pdf_name], names, html_iframe, state\n",
    "\n",
    "# ------------------------\n",
    "# Parsing helper (pair group mean/sd columns)\n",
    "# ------------------------\n",
    "def detect_group_mean_sd_headers(headers):\n",
    "    \"\"\"\n",
    "    Given headers list, detect pairs of mean/sd columns.\n",
    "    Expect header strings like '24-h group Mean', '24-h group SD'.\n",
    "    Return list of groups: [(group_label, mean_col, sd_col), ...]\n",
    "    mean_col/sd_col are header names (strings) or None.\n",
    "    \"\"\"\n",
    "    norm_map = {}\n",
    "    # normalize: remove tokens mean/sd and parentheses\n",
    "    for h in headers:\n",
    "        hstr = str(h).strip()\n",
    "        hnorm = re.sub(r'[\\(\\)\\[\\]\\{\\}]', ' ', hstr).strip()\n",
    "        low = hnorm.lower()\n",
    "        # detect role\n",
    "        if re.search(r'\\b(mean|avg|average|m|Âµ|mu)\\b', low):\n",
    "            role = 'mean'\n",
    "        elif re.search(r'\\b(sd|s\\.d|std|stddev|se|stderr)\\b', low):\n",
    "            role = 'sd'\n",
    "        else:\n",
    "            role = None\n",
    "        # compute prefix by removing role tokens\n",
    "        prefix = re.sub(r'\\b(mean|avg|average|m|Âµ|mu|sd|s\\.d|std|stddev|se|stderr)\\b', '', low).strip()\n",
    "        if prefix == '':\n",
    "            prefix = low  # fallback to full header\n",
    "        if prefix not in norm_map:\n",
    "            norm_map[prefix] = {'mean': None, 'sd': None, 'raw_prefix': prefix}\n",
    "        if role == 'mean':\n",
    "            norm_map[prefix]['mean'] = hstr\n",
    "        elif role == 'sd':\n",
    "            norm_map[prefix]['sd'] = hstr\n",
    "        else:\n",
    "            # unknown: keep as potential group header if no explicit mean/sd\n",
    "            if prefix not in norm_map:\n",
    "                norm_map[prefix] = {'mean': None, 'sd': None, 'raw_prefix': prefix}\n",
    "            # we don't set anything here\n",
    "    groups = []\n",
    "    for prefix, info in norm_map.items():\n",
    "        if info.get('mean') is not None or info.get('sd') is not None:\n",
    "            groups.append((prefix, info.get('mean'), info.get('sd')))\n",
    "    return groups\n",
    "\n",
    "# ------------------------\n",
    "# Analysis: compute per-row t (and show ranges with f_range)\n",
    "# ------------------------\n",
    "def analyze_selected_table(selected_table: str, selected_file: str, state: dict,\n",
    "                           detected_ns_json: str, assume_n_json: str, dp_p: int, show_t_flag: bool):\n",
    "    # prefer detected_ns_json (edited), else try assume_n_json\n",
    "    manual_ns_json = None\n",
    "    if detected_ns_json and detected_ns_json.strip():\n",
    "        manual_ns_json = detected_ns_json\n",
    "    elif assume_n_json and assume_n_json.strip():\n",
    "        manual_ns_json = assume_n_json\n",
    "    else:\n",
    "        manual_ns_json = None\n",
    "    \"\"\"\n",
    "    Parse currently selected table and compute per-row stats (t or F).\n",
    "    - manual_ns_json: optional editable JSON input (user override)\n",
    "    - dp_p: decimal places for rounding (-1 auto)\n",
    "    - show_t_flag: True => output t values (sqrt of F)\n",
    "    Returns:\n",
    "      - analysis_text: string summary\n",
    "      - result_df: pandas DataFrame ready to display in UI (one row per original row, with computed nominal/min/max)\n",
    "    \"\"\"\n",
    "    if not state or \"pdf_names\" not in state:\n",
    "        return \"No state present. Run extraction first.\", pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        file_idx = state[\"pdf_names\"].index(selected_file)\n",
    "    except ValueError:\n",
    "        return \"Selected file not in state.\", pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        tbl_idx = state[\"table_names\"][file_idx].index(selected_table)\n",
    "    except ValueError:\n",
    "        return \"Selected table not found in state.\", pd.DataFrame()\n",
    "\n",
    "    df = state[\"tables\"][file_idx][tbl_idx].copy()\n",
    "    headers = list(df.columns)\n",
    "\n",
    "    # 1) detect groups (mean/sd column pairs)\n",
    "    groups = detect_group_mean_sd_headers(headers)\n",
    "    if len(groups) < 2:\n",
    "        # try fallback: maybe columns are \"GroupA Mean\", \"GroupA SD\", \"GroupB Mean\", ...\n",
    "        return \"Could not detect at least two group mean/sd pairs in headers. Ensure LLM split mean and sd into separate columns.\", pd.DataFrame()\n",
    "\n",
    "    # 2) build mapping header->group name and locate mean/sd column names\n",
    "    group_labels = [g[0] for g in groups]\n",
    "    mean_cols = [g[1] for g in groups]\n",
    "    sd_cols = [g[2] for g in groups]\n",
    "\n",
    "    # 3) Load Ns: priority order\n",
    "    #   a) manual override JSON in UI (if provided)\n",
    "    #   b) LLM-provided state[\"table_ns\"]\n",
    "    #   c) try to find Ns inside cells (simple heuristics)\n",
    "    override_ns = {}\n",
    "    if manual_ns_json:\n",
    "        try:\n",
    "            parsed = json.loads(manual_ns_json)\n",
    "            if isinstance(parsed, dict):\n",
    "                override_ns = {str(k): int(v) for k, v in parsed.items()}\n",
    "        except Exception:\n",
    "            # invalid JSON - ignore and continue to other sources (we'll inform user)\n",
    "            override_ns = {}\n",
    "\n",
    "    llm_ns_map = {}\n",
    "    if \"table_ns\" in state:\n",
    "        try:\n",
    "            llm_ns_map = state[\"table_ns\"][file_idx][tbl_idx]\n",
    "        except Exception:\n",
    "            llm_ns_map = {}\n",
    "\n",
    "    # merged ns_map (fallback)\n",
    "    ns_map = {}\n",
    "    for label, mcol, scol in groups:\n",
    "        # try manual override exact match or fuzzy match\n",
    "        n_val = None\n",
    "        # exact label keys first\n",
    "        if label in override_ns:\n",
    "            n_val = int(override_ns[label])\n",
    "        else:\n",
    "            # fuzzy: try to find a key in override_ns that matches prefix\n",
    "            for k in override_ns:\n",
    "                if k.lower() in label.lower() or label.lower() in k.lower():\n",
    "                    n_val = int(override_ns[k]); break\n",
    "        if n_val is None:\n",
    "            # try LLM-provided\n",
    "            if label in llm_ns_map and llm_ns_map[label] is not None:\n",
    "                n_val = int(llm_ns_map[label])\n",
    "            else:\n",
    "                # fuzzy match\n",
    "                for k in llm_ns_map:\n",
    "                    if k.lower() in label.lower() or label.lower() in k.lower():\n",
    "                        n_val = llm_ns_map[k]\n",
    "                        if n_val is not None:\n",
    "                            n_val = int(n_val)\n",
    "                        break\n",
    "        # finally try to detect an N in mean or sd column values (like '56 (89.6%)')\n",
    "        if n_val is None:\n",
    "            for c in (mcol, scol):\n",
    "                if c is None or c not in df.columns:\n",
    "                    continue\n",
    "                vals = []\n",
    "                for cell in df[c].astype(str):\n",
    "                    if not cell or cell.strip() == \"\":\n",
    "                        continue\n",
    "                    m = re.match(r'^\\s*(\\d+)\\s*\\(\\s*[0-9\\.]+%?\\s*\\)\\s*$', cell.strip())\n",
    "                    if m:\n",
    "                        vals.append(int(m.group(1)))\n",
    "                if len(vals) > 0:\n",
    "                    # choose the most common\n",
    "                    vals_u, counts = np.unique(vals, return_counts=True)\n",
    "                    n_val = int(vals_u[np.argmax(counts)])\n",
    "                    break\n",
    "        ns_map[label] = n_val\n",
    "\n",
    "    # check any missing\n",
    "    missing_ns = [k for k, v in ns_map.items() if v is None]\n",
    "    if missing_ns:\n",
    "        # Ask user to provide Ns via manual override; present parsed preview\n",
    "        parsed_preview = {\n",
    "            \"means_headers\": mean_cols,\n",
    "            \"sd_headers\": sd_cols,\n",
    "            \"detected_ns\": ns_map,\n",
    "            \"labels\": group_labels\n",
    "        }\n",
    "        return (\"Missing sample sizes for groups: \" + \", \".join(missing_ns) +\n",
    "                \". Provide Ns in the 'Assume N' box as JSON map (e.g. {\\\"24-h group\\\":56, \\\"72-h group\\\":51}).\\n\\n\"\n",
    "                \"Parsed preview:\\n\" + json.dumps(parsed_preview, indent=2)), pd.DataFrame()\n",
    "\n",
    "    # 4) For each row, compute t (2-group case) or F (k-group case) & ranges using f_range\n",
    "    results = []\n",
    "    num_groups = len(groups)\n",
    "    for ridx, row in df.iterrows():\n",
    "        # build per-group mean and sd for this row\n",
    "        mvals = []\n",
    "        svals = []\n",
    "        nvals = []\n",
    "        for label, mcol, scol in groups:\n",
    "            # parse mean\n",
    "            mean_val = np.nan\n",
    "            sd_val = np.nan\n",
    "            # mean column may be None (rare) - try to find best candidate\n",
    "            if mcol and mcol in df.columns:\n",
    "                cell = df.at[ridx, mcol]\n",
    "                parsed = parse_mean_sd_cell(cell)\n",
    "                if parsed:\n",
    "                    mean_val = parsed[0]\n",
    "                    # if parsed sd and separate sd col also exists, prefer separate sd col\n",
    "                    if parsed[1] is not None and (not scol or scol not in df.columns):\n",
    "                        sd_val = parsed[1]\n",
    "                else:\n",
    "                    try:\n",
    "                        mean_val = float(str(cell).strip())\n",
    "                    except:\n",
    "                        mean_val = np.nan\n",
    "            # parse sd if separate column exists\n",
    "            if scol and scol in df.columns:\n",
    "                scell = df.at[ridx, scol]\n",
    "                if pd.isna(scell) or str(scell).strip()==\"\":\n",
    "                    pass\n",
    "                else:\n",
    "                    parsed2 = re.search(r'([+-]?\\d+(?:\\.\\d+)?)', str(scell))\n",
    "                    if parsed2:\n",
    "                        try:\n",
    "                            sd_val = float(parsed2.group(1))\n",
    "                        except:\n",
    "                            pass\n",
    "            # if sd still nan and mean column had sd, keep that\n",
    "            if np.isnan(sd_val):\n",
    "                # try to re-parse from mean column if not yet done\n",
    "                if mcol and mcol in df.columns:\n",
    "                    parsed = parse_mean_sd_cell(df.at[ridx, mcol])\n",
    "                    if parsed:\n",
    "                        sd_val = parsed[1]\n",
    "\n",
    "            mvals.append(mean_val)\n",
    "            svals.append(sd_val)\n",
    "            nvals.append(ns_map[label])\n",
    "\n",
    "        # call f_range for this single-row case\n",
    "        try:\n",
    "            r = f_range(m=mvals, s=svals, n=nvals, title=f\"{selected_file} - {selected_table} - row {ridx}\",\n",
    "                        show_t=show_t_flag, dp_p=dp_p)\n",
    "            # f_range returns arrays for nominal/min/max; for one-way with k groups we may get len>1 (F_A etc.)\n",
    "            # For simple 2-group one-way, r['nominal'][0] is t (if show_t=True) or F (if show_t=False)\n",
    "            nominal = r['nominal']\n",
    "            mn = r['min']\n",
    "            mx = r['max']\n",
    "            # produce row label if first column is row header\n",
    "            row_label = None\n",
    "            first_col = df.columns[0] if len(df.columns)>0 else None\n",
    "            if first_col:\n",
    "                row_label = str(df.at[ridx, first_col])\n",
    "            results.append({\n",
    "                \"row_index\": int(ridx),\n",
    "                \"row_label\": row_label,\n",
    "                \"nominal\": nominal,\n",
    "                \"min\": mn,\n",
    "                \"max\": mx,\n",
    "                \"dp_used\": r['dp'],\n",
    "                \"enumeration_mode\": r['enumeration_mode'],\n",
    "                \"total_combinations\": r['total_combinations']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"row_index\": int(ridx),\n",
    "                \"row_label\": str(df.at[ridx, df.columns[0]]) if df.shape[1]>0 else f\"row{ridx}\",\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "\n",
    "    # Build result DataFrame convenient for display\n",
    "    rows_out = []\n",
    "    for item in results:\n",
    "        if 'error' in item:\n",
    "            rows_out.append({\n",
    "                \"row_index\": item[\"row_index\"],\n",
    "                \"row_label\": item.get(\"row_label\"),\n",
    "                \"error\": item[\"error\"]\n",
    "            })\n",
    "            continue\n",
    "        # join arrays into readable strings (nom/min/max for each effect)\n",
    "        nominal_str = \", \".join([str(round(x,6)) if x is not None else \"NA\" for x in item[\"nominal\"]])\n",
    "        min_str = \", \".join([str(round(x,6)) if x is not None else \"NA\" for x in item[\"min\"]])\n",
    "        max_str = \", \".join([str(round(x,6)) if x is not None else \"NA\" for x in item[\"max\"]])\n",
    "        rows_out.append({\n",
    "            \"row_index\": item[\"row_index\"],\n",
    "            \"row_label\": item.get(\"row_label\"),\n",
    "            \"nominal\": nominal_str,\n",
    "            \"min\": min_str,\n",
    "            \"max\": max_str,\n",
    "            \"dp\": item[\"dp_used\"],\n",
    "            \"enumeration_mode\": item[\"enumeration_mode\"],\n",
    "            \"total_combinations\": item[\"total_combinations\"]\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(rows_out)\n",
    "\n",
    "    # Compose summary text\n",
    "    summary_lines = []\n",
    "    summary_lines.append(f\"Analysis for table: {selected_table} (file: {selected_file})\")\n",
    "    summary_lines.append(f\"Groups detected (label order): {', '.join(group_labels)}\")\n",
    "    summary_lines.append(\"Note: nominal/min/max may contain multiple values (one per tested effect).\")\n",
    "    summary_text = \"\\n\".join(summary_lines)\n",
    "\n",
    "    return summary_text, result_df\n",
    "\n",
    "# ------------------------\n",
    "# Gradio UI\n",
    "# ------------------------\n",
    "def combined_extract(mode, method, files):\n",
    "    # File upload methods\n",
    "\n",
    "    if mode==\"File Upload\" and method==\"AI\":\n",
    "        file_names, table_names, html_iframe, state = extract_ai_data(files)\n",
    "        return gr.update(choices=file_names, value=file_names[0] if file_names else None), gr.update(choices=table_names, value=table_names[0] if table_names else None), html_iframe, state\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## ðŸ“‘ table extraction + t/F analysis (LLM-detected Ns with editable override)\")\n",
    "\n",
    "    mode    = gr.Radio([\"File Upload\"], value=\"File Upload\", label=\"Mode\")\n",
    "    method = gr.Radio([\"AI\"], value=\"AI\", label=\"File Upload Method\")\n",
    "    files   = gr.File(file_count=\"multiple\", type=\"filepath\", label=\"Upload PDF(s)\")\n",
    "\n",
    "    file_selector  = gr.Dropdown(label=\"Select PDF\",   choices=[], value=None)\n",
    "    table_selector = gr.Dropdown(label=\"Select Table\", choices=[], value=None)\n",
    "    state = gr.State({})\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            pdf_preview = gr.HTML(label=\"PDF Preview\")\n",
    "            # show detected Ns for the selected table (LLM)\n",
    "            detected_ns_box = gr.Textbox(label=\"Detected Ns (from LLM) - click 'Load detected Ns' then edit if needed\", lines=3)\n",
    "            load_ns_btn = gr.Button(\"Load detected Ns for selected table\")\n",
    "        with gr.Column(scale=1):\n",
    "            table_view = gr.Dataframe(label=\"Extracted Table (select a row to inspect)\", interactive=True)\n",
    "            dl_trigger = gr.Button(\"Download CSV\")\n",
    "            download_btn = gr.File(label=\"\", file_count=\"single\", type=\"filepath\", visible=False)\n",
    "\n",
    "    # Analysis panel\n",
    "    gr.Markdown(\"### Analysis Controls\")\n",
    "    assume_n_input = gr.Textbox(label=\"Manual Ns override (JSON dict) e.g. {\\\"24-h group\\\":56, \\\"72-h group\\\":51}\", placeholder='{\"24-h group\":56,\"72-h group\":51}', lines=2)\n",
    "    dp_input = gr.Number(value=-1, label=\"dp (decimal places) (-1 = auto)\", precision=0)\n",
    "    show_t_checkbox = gr.Checkbox(value=True, label=\"Show t (sqrt of F)\")\n",
    "    analyze_btn = gr.Button(\"Analyze selected table\")\n",
    "    analysis_output = gr.Textbox(label=\"Analysis Summary\", lines=6)\n",
    "    analysis_df = gr.Dataframe(label=\"Per-row results\", interactive=False)\n",
    "\n",
    "    def on_download(selected_table, selected_file, st):\n",
    "        if not st:\n",
    "            return \"\"\n",
    "        fidx = st[\"pdf_names\"].index(selected_file)\n",
    "        tidx = st[\"table_names\"][fidx].index(selected_table)\n",
    "        df = st[\"tables\"][fidx][tidx]\n",
    "        csv_path = f\"{selected_file}_{selected_table}.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        return csv_path\n",
    "\n",
    "    dl_trigger.click(fn=on_download, inputs=[table_selector, file_selector, state], outputs=[download_btn])\n",
    "\n",
    "    # Wire extraction button\n",
    "    extract_btn = gr.Button(\"Extract\")\n",
    "    extract_btn.click(fn=combined_extract,\n",
    "                      inputs=[mode, method, files],\n",
    "                      outputs=[file_selector, table_selector, pdf_preview, state])\n",
    "\n",
    "    # file/table selection callbacks\n",
    "    def on_file_change(selected_file: str, st: dict):\n",
    "        if not st:\n",
    "            return gr.update(choices=[], value=None), \"\", pd.DataFrame()\n",
    "        file_idx = st[\"pdf_names\"].index(selected_file)\n",
    "        iframe_html = st[\"iframes\"][file_idx]\n",
    "        names = st[\"table_names\"][file_idx]\n",
    "        df0 = st[\"tables\"][file_idx][0] if names else pd.DataFrame()\n",
    "        return gr.update(choices=names, value=names[0] if names else None), iframe_html, df0\n",
    "\n",
    "    file_selector.change(fn=on_file_change, inputs=[file_selector, state], outputs=[table_selector, pdf_preview, table_view])\n",
    "\n",
    "    def on_table_change(selected_table: str, selected_file: str, st: dict):\n",
    "        if not st:\n",
    "            return pd.DataFrame()\n",
    "        file_idx = st[\"pdf_names\"].index(selected_file)\n",
    "        tbl_idx  = st[\"table_names\"][file_idx].index(selected_table)\n",
    "        return st[\"tables\"][file_idx][tbl_idx]\n",
    "\n",
    "    table_selector.change(fn=on_table_change, inputs=[table_selector, file_selector, state], outputs=[table_view])\n",
    "\n",
    "    # Load detected Ns into the editable textbox\n",
    "    def load_detected_ns(selected_table, selected_file, st):\n",
    "        if not st:\n",
    "            return \"\"\n",
    "        try:\n",
    "            file_idx = st[\"pdf_names\"].index(selected_file)\n",
    "            tbl_idx = st[\"table_names\"][file_idx].index(selected_table)\n",
    "            ns_map = st.get(\"table_ns\", [[{}]])[file_idx][tbl_idx]\n",
    "            return json.dumps(ns_map, indent=2)\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    load_ns_btn.click(fn=load_detected_ns, inputs=[table_selector, file_selector, state], outputs=[detected_ns_box])\n",
    "\n",
    "    # Analysis button wires to analyzer\n",
    "    analyze_btn.click(fn=analyze_selected_table,\n",
    "                  inputs=[table_selector, file_selector, state, detected_ns_box, assume_n_input, dp_input, show_t_checkbox],\n",
    "                  outputs=[analysis_output, analysis_df])\n",
    "\n",
    "    app.launch(share=True,debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
